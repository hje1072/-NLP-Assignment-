{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hje1072/-NLP-Assignment-/blob/main/%5BNLP%5D_Lab_2_2_MLP_Examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UrSIk1b-59q9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "seed = 1337\n",
        "\n",
        "#같은값으로 고정\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn1JaT9d59q_"
      },
      "source": [
        "### Example 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aV8tOoM659rA"
      },
      "outputs": [],
      "source": [
        "class MultilayerPerceptron(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim): #init=생성자\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_dim (int): the size of the input vectors\n",
        "            hidden_dim (int): the output size of the first Linear layer\n",
        "            output_dim (int): the output size of the second Linear layer\n",
        "        \"\"\"\n",
        "        super(MultilayerPerceptron, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x_in, apply_softmax=False):\n",
        "        \"\"\"The forward pass of the MLP\n",
        "\n",
        "        Args:\n",
        "            x_in (torch.Tensor): an input data tensor.\n",
        "                x_in.shape should be (batch, input_dim)\n",
        "            apply_softmax (bool): a flag for the softmax activation\n",
        "                should be false if used with the Cross Entropy losses\n",
        "        Returns:\n",
        "            the resulting tensor. tensor.shape should be (batch, output_dim)\n",
        "        \"\"\"\n",
        "        intermediate = F.relu(self.fc1(x_in))\n",
        "        output = self.fc2(intermediate)\n",
        "\n",
        "        if apply_softmax:\n",
        "            output = F.softmax(output, dim=1)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CNHcLKV59rB"
      },
      "source": [
        "### Example 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aM_ANUXw59rB",
        "outputId": "74d995e6-6c41-42e0-a221-b1fec52fc230",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultilayerPerceptron(\n",
            "  (fc1): Linear(in_features=3, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "batch_size = 2 # number of samples input at once\n",
        "input_dim = 3\n",
        "hidden_dim = 100\n",
        "output_dim = 4\n",
        "\n",
        "# Initialize model\n",
        "mlp = MultilayerPerceptron(input_dim, hidden_dim, output_dim)\n",
        "print(mlp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENjuYT4959rC"
      },
      "source": [
        "### Example 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hXYUrfTj59rC"
      },
      "outputs": [],
      "source": [
        "def describe(x):\n",
        "    print(\"Type: {}\".format(x.type()))\n",
        "    print(\"Shape/size: {}\".format(x.shape))\n",
        "    print(\"Values: \\n{}\".format(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ni2-q4DF59rC",
        "outputId": "38b2d22c-7e66-43f2-d3b6-569f5a2e999b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0.1348, 0.2115, 0.2435],\n",
            "        [0.3794, 0.4826, 0.0375]])\n"
          ]
        }
      ],
      "source": [
        "# Inputs\n",
        "x_input = torch.rand(batch_size, input_dim)\n",
        "describe(x_input)\n",
        "#2개씩 묶어 보기."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_i_xOTEP59rC",
        "outputId": "3fcf70fb-7e44-4775-9a91-463c89f94b9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 4])\n",
            "Values: \n",
            "tensor([[-0.2456,  0.0723,  0.1589, -0.3294],\n",
            "        [-0.3497,  0.0828,  0.3391, -0.4271]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "y_output = mlp(x_input, apply_softmax=False)\n",
        "describe(y_output)\n",
        "#4개의 out풋에서 연관성이 어느정도 있는지 보여주기."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj_pb_fF59rD"
      },
      "source": [
        "### Example 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PiAanR1i59rD",
        "outputId": "f3d3468f-be2a-4c72-f851-637b4d309b16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 4])\n",
            "Values: \n",
            "tensor([[0.2087, 0.2868, 0.3127, 0.1919],\n",
            "        [0.1832, 0.2824, 0.3649, 0.1696]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "y_output = mlp(x_input, apply_softmax=True)\n",
        "describe(y_output)ㅂ\n",
        "\n",
        "#4개의 아웃풋중 어디에 속할지 확률 나누기 / 그래서 합치면 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJDAB1i459rD"
      },
      "source": [
        "### Example 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O1fLeYpx59rD",
        "outputId": "9c7a4a79-773d-4375-e2e3-5187cbd5a6a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultilayerPerceptron(\n",
            "  (fc1): Linear(in_features=3, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 4])\n",
            "Values: \n",
            "tensor([[ 0.0193,  0.0275,  0.2319,  0.3032],\n",
            "        [-0.5323,  0.3183,  0.4194, -0.0205]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "class MultilayerPerceptron(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_dim (int): the size of the input vectors\n",
        "            hidden_dim (int): the output size of the first Linear layer\n",
        "            output_dim (int): the output size of the second Linear layer\n",
        "        \"\"\"\n",
        "        super(MultilayerPerceptron, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x_in, apply_softmax=False):\n",
        "        \"\"\"The forward pass of the MLP\n",
        "\n",
        "        Args:\n",
        "            x_in (torch.Tensor): an input data tensor.\n",
        "                x_in.shape should be (batch, input_dim)\n",
        "            apply_softmax (bool): a flag for the softmax activation\n",
        "                should be false if used with the Cross Entropy losses\n",
        "        Returns:\n",
        "            the resulting tensor. tensor.shape should be (batch, output_dim)\n",
        "        \"\"\"\n",
        "        intermediate = F.relu(self.fc1(x_in))\n",
        "        output = self.fc2(F.dropout(intermediate, p=0.5))\n",
        "\n",
        "        if apply_softmax:\n",
        "            output = F.softmax(output, dim=1)\n",
        "        return output\n",
        "\n",
        "batch_size = 2 # number of samples input at once\n",
        "input_dim = 3\n",
        "hidden_dim = 100\n",
        "output_dim = 4\n",
        "\n",
        "# Initialize model\n",
        "mlp = MultilayerPerceptron(input_dim, hidden_dim, output_dim)\n",
        "print(mlp)\n",
        "\n",
        "y_output = mlp(x_input, apply_softmax=False)\n",
        "describe(y_output)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nlpbook",
      "language": "python",
      "name": "nlpbook"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}